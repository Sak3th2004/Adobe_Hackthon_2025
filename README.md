# Adobe Challenge 1B â€“ Semantic Search over PDF Collections

This project performs semantic search over multiple PDF collections to extract answers based on persona and job context using OpenAI embeddings and LlamaIndex. It's containerized using Docker and runs on CPU.

---

## ğŸ“ Folder Structure

ADOBE_1B/
â”œâ”€â”€ input/
â”‚ â””â”€â”€ pdfs/
â”‚ â”œâ”€â”€ collection 1/
â”‚ â”œâ”€â”€ collection 2/
â”‚ â””â”€â”€ collection 3/
â”œâ”€â”€ Collection1/ # Output files for Collection 1
â”œâ”€â”€ Collection2/ # Output files for Collection 2
â”œâ”€â”€ Collection3/ # Output files for Collection 3
â”œâ”€â”€ main.py # Main semantic search pipeline
â”œâ”€â”€ Dockerfile # Docker configuration
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ execution_instruction.txt
â””â”€â”€ README.md # This file


---

## âš™ï¸ How It Works

- The PDFs from each collection directory are analyzed semantically using OpenAI embeddings and LlamaIndex.
- The application takes a defined `persona`, `job`, and `query` for each collection and generates answers based on the document content.
- Answers are saved in JSON format under the respective output folders.

---

## ğŸ§  Example Persona Input

Each collection has a query input structured like:

```json
{
  "persona": "A 25-year-old fitness enthusiast...",
  "job": "Personal trainer",
  "query": "Dinner ideas"
}

Docker Setup
Step 1: Build Docker Image
docker build --platform linux/amd64 -t adobe:challenge1b .
 Step 2: Run the Container
 docker run --platform linux/amd64 -it --rm adobe:challenge1b
